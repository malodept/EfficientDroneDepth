{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# EfficientDroneDepth \u2014 Drive-aware Training\nRun on real **TartanAir/AbandonedFactory** if found on Drive, otherwise auto-download the minimal subset and train end-to-end.\n**Order:** Setup \u2192 Data \u2192 Remap \u2192 Train \u2192 Eval/Export \u2192 Figures.\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 1) Setup"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["# Install deps\n!pip -q install torch torchvision timm numpy opencv-python scikit-image onnx onnxruntime rich matplotlib tartanair\n\nimport torch, platform, sys, os\nprint(\"torch\", torch.__version__, \"cuda\", torch.cuda.is_available(), platform.platform())\n\n# Mount Drive\nfrom google.colab import drive\ndrive.mount('/content/drive', force_remount=True)\n\n# Clone fresh\n%cd /content\n!rm -rf efficientdronedepth\n!git clone --depth 1 https://github.com/malodept/EfficientDroneDepth.git efficientdronedepth\n%cd /content/efficientdronedepth\nif \"/content/efficientdronedepth\" not in sys.path:\n    sys.path.append(\"/content/efficientdronedepth\")\n\n# Persist runs to Drive\nOUT=\"/content/drive/MyDrive/edd_runs_abandoned\"\nos.makedirs(OUT, exist_ok=True)\n!rm -rf runs && ln -s \"$OUT\" runs && ls -la runs\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 2) Data \u2014 detect or download"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["import os, pathlib, shutil\nfrom tartanair import tartanair as ta\n\nDRIVE_ROOT = '/content/drive/MyDrive/tartanair_subset'\nENV_DIR = os.path.join(DRIVE_ROOT, 'AbandonedFactory')\nDATA_OMNI = os.path.join(ENV_DIR, 'Data_omni')\nos.makedirs(DRIVE_ROOT, exist_ok=True)\n\npresent = os.path.exists(DATA_OMNI) and any(\n    os.path.isdir(os.path.join(DATA_OMNI, p)) for p in ['P0000','P0001','P0002','P0004','P0005']\n)\nprint(\"Dataset present:\", present)\n\nif not present:\n    ta.init(DRIVE_ROOT)\n    ta.download_ground(\n        env=[\"AbandonedFactory\"],\n        version=['omni'],\n        traj=[],\n        modality=['image', 'depth'],\n        camera_name=['lcam_front'],\n        unzip=True\n    )\n    print(\"Downloaded to:\", DRIVE_ROOT)\nelse:\n    print(\"Using existing dataset at:\", DRIVE_ROOT)\n\n!ls -R $DRIVE_ROOT/AbandonedFactory | head -n 60\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 3) Remap layout to loader format"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["import re\n\nROOT = os.path.join(DRIVE_ROOT, \"AbandonedFactory\", \"Data_omni\")\nseqs = [d for d in os.listdir(ROOT) if re.match(r\"P\\d{4}\", d)]\nprint(\"Found sequences:\", seqs)\n\ndef fix_seq(pseq):\n    import pathlib, shutil\n    src_img = pathlib.Path(ROOT)/pseq/\"image_lcam_front\"\n    src_dep = pathlib.Path(ROOT)/pseq/\"depth_lcam_front\"\n    if not src_img.exists() or not src_dep.exists():\n        return\n    dst_left  = pathlib.Path(ROOT)/pseq/\"left\"\n    dst_depth = pathlib.Path(ROOT)/pseq/\"depth\"\n    dst_left.mkdir(exist_ok=True)\n    dst_depth.mkdir(exist_ok=True)\n    for f in sorted(src_img.glob(\"*.png\")):\n        stem = f.stem.replace(\"_lcam_front\",\"\")\n        out = dst_left/f\"{stem}_left.png\"\n        if not out.exists(): shutil.copy2(f, out)\n    for f in sorted(src_dep.glob(\"*.png\")):\n        stem = f.stem.replace(\"_lcam_front_depth\",\"\")\n        out = dst_depth/f\"{stem}_depth.png\"\n        if not out.exists(): shutil.copy2(f, out)\n\nfor s in seqs:\n    fix_seq(s)\n\nprint(\"Remap done.\")\n!find \"$DRIVE_ROOT/AbandonedFactory/Data_omni\" -maxdepth 2 -type d -name left -o -name depth | sed 's/^/ - /' | head -n 20\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 4) Sanity check model forward"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["from src.edd.modeling import DPTSmall\nimport torch\nm = DPTSmall(pretrained=False)\nx = torch.randn(2,3,384,384)\ny = m(x)\nprint(\"Output shape:\", tuple(y.shape))\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 5) Train"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["DATA_ROOT = \"/content/drive/MyDrive/tartanair_subset/AbandonedFactory\"\nprint(\"DATA_ROOT =\", DATA_ROOT)\n\nepochs, batch, img_sz = 12, 8, 384\n!python -m src.edd.train --data_root $DATA_ROOT --epochs {epochs} --batch_size {batch} --img_size {img_sz}\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 6) Evaluate + Export"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["!python -m src.edd.eval --data_root $DATA_ROOT --ckpt runs/edd_midas.pt --bench\n!python -m src.edd.export_onnx --ckpt runs/edd_midas.pt --onnx runs/edd_midas.onnx\n!python -m src.edd.quantize_dynamic --onnx runs/edd_midas.onnx --out runs/edd_midas_int8.onnx\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 7) Save sample predictions"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["import os, torch, cv2\nfrom src.edd.modeling import DPTSmall\nfrom src.edd.data import TartanAirDepth\n\nos.makedirs(\"runs/figures\", exist_ok=True)\nm = DPTSmall(pretrained=False).eval()\nm.load_state_dict(torch.load(\"runs/edd_midas.pt\", map_location=\"cpu\")[\"model\"], strict=False)\n\nds = TartanAirDepth(DATA_ROOT, img_size=384, limit_samples=50, train=False)\nn = min(4, len(ds))\nfor i in range(n):\n    ex = ds[i]\n    y = m(ex[\"image\"].unsqueeze(0)).squeeze().detach().numpy()\n    y = (y / (y.max() + 1e-6) * 255).astype(\"uint8\")\n    cv2.imwrite(f\"runs/figures/pred_{i}.png\", y)\nprint(\"saved:\", n, \"figures \u2192 runs/figures/\")\n"]}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3", "language": "python"}, "language_info": {"name": "python", "version": "3.10"}}, "nbformat": 4, "nbformat_minor": 5}